{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from utils.cnn_gru import Decoder\n",
    "from utils.dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "EPOCHS = 1\n",
    "lr = 3e-4\n",
    "weight_decay = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 239, 43])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Decoder(in_feature_dim=12, conv_kernel=2, conv_stride=2, hidden_dim=32, num_layers=3, vocab_size=43)\n",
    "decoder = decoder.to(device)\n",
    "\n",
    "# batch_size, temporal_dim, feature_dim\n",
    "test_input = torch.randn((1, 479, 12)).to(device)\n",
    "\n",
    "output = decoder(test_input)\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num samples: 460\n",
      "Loading phoneme data...\n",
      "Vocab length: 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  1,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11,  3, 12,  3, 13, 14,\n",
       "         6,  5, 15, 16, 17, 14,  5, 18, 14,  3,  6, 19, 13, 20,  5, 13, 21,  5,\n",
       "         6, 11, 22,  6,  5, 14, 11, 12, 19,  7, 10, 23, 24, 12,  2,  1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "dataset = Dataset(\"./data/cin_us_faet0/\")\n",
    "\n",
    "sample = next(iter(dataset))\n",
    "\n",
    "sample[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = torch.utils.data.random_split(dataset, [0.8, 0.2])\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer + loss initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "\n",
    "# ctc blank label is 0\n",
    "criterion = nn.CTCLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/368 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 368/368 [00:08<00:00, 45.08it/s]\n",
      "  5%|▌         | 20/368 [00:00<00:00, 394.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.5007530621119907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [00:00<00:00, 367.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 3.4973837240882544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_steps = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # decoder train\n",
    "    decoder.train()\n",
    "\n",
    "    for ema_data, phone_sequences, seq_lengths in tqdm(train_loader):\n",
    "        ema_data = ema_data.to(device)\n",
    "        phone_sequences = phone_sequences.to(device)\n",
    "\n",
    "        output = decoder(ema_data)\n",
    "\n",
    "        # for ctc loss\n",
    "        output = output.permute(1, 0, 2)\n",
    "\n",
    "        loss = criterion(output, phone_sequences, torch.full((output.shape[1],), output.shape[0]), seq_lengths)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # decoder evaluation\n",
    "    decoder.eval()\n",
    "\n",
    "    train_losses = []\n",
    "    for _, (ema_data, phone_sequences, seq_lengths) in enumerate(tqdm(train_loader)):\n",
    "        ema_data = ema_data.to(device)\n",
    "        phone_sequences = phone_sequences.to(device)\n",
    "\n",
    "        output = decoder(ema_data)\n",
    "\n",
    "        # for ctc loss\n",
    "        output = output.permute(1, 0, 2)\n",
    "\n",
    "        loss = criterion(output, phone_sequences, torch.full((output.shape[1],), output.shape[0]), seq_lengths)\n",
    "\n",
    "        train_losses += [loss.item()]\n",
    "\n",
    "        if _ == num_steps:\n",
    "            print(\"Train loss: \" + str(np.mean(np.array(train_losses))))\n",
    "            break\n",
    "\n",
    "    val_losses = []\n",
    "    for ema_data, phone_sequences, seq_lengths in tqdm(val_loader):\n",
    "        ema_data = ema_data.to(device)\n",
    "        phone_sequences = phone_sequences.to(device)\n",
    "\n",
    "        output = decoder(ema_data)\n",
    "\n",
    "        # for ctc loss\n",
    "        output = output.permute(1, 0, 2)\n",
    "\n",
    "        loss = criterion(output, phone_sequences, torch.full((output.shape[1],), output.shape[0]), seq_lengths)\n",
    "\n",
    "        val_losses += [loss.item()]\n",
    "    print(\"Val loss: \" + str(np.mean(np.array(val_losses))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssl-gesture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
